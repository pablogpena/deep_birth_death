{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-08T08:58:47.662143Z",
     "start_time": "2025-07-08T08:58:47.589359Z"
    }
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/workspace/phylo_estimation/data_inference')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-08T10:17:45.729383Z",
     "start_time": "2025-07-08T10:17:45.658414Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import itertools\n",
    "import time\n",
    "import os\n",
    "import statistics\n",
    "from time import time\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from evaluation.regression import generate_reg_results, get_regression_norm_results, get_regression_div_results, new_get_regression_div_results\n",
    "\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-08T08:58:49.268915Z",
     "start_time": "2025-07-08T08:58:49.203714Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.options.display.float_format = \"{:,.4f}\".format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-08T08:58:51.717557Z",
     "start_time": "2025-07-08T08:58:50.258424Z"
    }
   },
   "outputs": [],
   "source": [
    "pickle_base = '/workspace/phylo_estimation/data_inference/pickles/old_sims/dataset_'\n",
    "res_path = \"/workspace/phylo_estimation/data_inference/models/reg/\"\n",
    "n_tips = ['674', '489', '87']\n",
    "\n",
    "data = dict()\n",
    "for i in n_tips:\n",
    "    with open(pickle_base + i + \"_10k.pkl\", 'rb') as f:\n",
    "        data[i] = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-08T08:58:51.780127Z",
     "start_time": "2025-07-08T08:58:51.719512Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6000, 674)\n"
     ]
    }
   ],
   "source": [
    "print(data['674']['X_test'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-08T09:47:21.328063Z",
     "start_time": "2025-07-08T09:46:59.574645Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 674 tips ---\n",
      "BD\n",
      "--- Inference time:  BD scenario & norm 0.20946669578552246 seconds ---\n",
      "--- Inference time:  BD scenario & no_norm 0.20560646057128906 seconds ---\n",
      "HE\n",
      "--- Inference time:  HE scenario & norm 0.20915651321411133 seconds ---\n",
      "--- Inference time:  HE scenario & no_norm 0.15805554389953613 seconds ---\n",
      "ME\n",
      "--- Inference time:  ME scenario & norm 0.17746281623840332 seconds ---\n",
      "--- Inference time:  ME scenario & no_norm 0.17595911026000977 seconds ---\n",
      "SAT\n",
      "--- Inference time:  SAT scenario & norm 0.19025230407714844 seconds ---\n",
      "--- Inference time:  SAT scenario & no_norm 0.1393575668334961 seconds ---\n",
      "SR\n",
      "--- Inference time:  SR scenario & norm 0.1877448558807373 seconds ---\n",
      "(1020, 5)\n",
      "AAAAAAAAAAAA\n",
      "--- Inference time:  SR scenario & no_norm 0.18520355224609375 seconds ---\n",
      "WW\n",
      "--- Inference time:  WW scenario & norm 0.18587708473205566 seconds ---\n",
      "(986, 5)\n",
      "AAAAAAAAAAAA\n",
      "--- Inference time:  WW scenario & no_norm 0.1889641284942627 seconds ---\n",
      "--- 489 tips ---\n",
      "BD\n",
      "--- Inference time:  BD scenario & norm 0.13639163970947266 seconds ---\n",
      "--- Inference time:  BD scenario & no_norm 0.1306154727935791 seconds ---\n",
      "HE\n",
      "--- Inference time:  HE scenario & norm 0.13832998275756836 seconds ---\n",
      "--- Inference time:  HE scenario & no_norm 0.12534713745117188 seconds ---\n",
      "ME\n",
      "--- Inference time:  ME scenario & norm 0.1494152545928955 seconds ---\n",
      "--- Inference time:  ME scenario & no_norm 0.1513991355895996 seconds ---\n",
      "SAT\n",
      "--- Inference time:  SAT scenario & norm 0.11492514610290527 seconds ---\n",
      "--- Inference time:  SAT scenario & no_norm 0.1191110610961914 seconds ---\n",
      "SR\n",
      "--- Inference time:  SR scenario & norm 0.1528944969177246 seconds ---\n",
      "(992, 5)\n",
      "AAAAAAAAAAAA\n",
      "--- Inference time:  SR scenario & no_norm 0.15126419067382812 seconds ---\n",
      "WW\n",
      "--- Inference time:  WW scenario & norm 0.14983820915222168 seconds ---\n",
      "(980, 5)\n",
      "AAAAAAAAAAAA\n",
      "--- Inference time:  WW scenario & no_norm 0.14856243133544922 seconds ---\n",
      "--- 87 tips ---\n",
      "BD\n",
      "--- Inference time:  BD scenario & norm 0.1130523681640625 seconds ---\n",
      "--- Inference time:  BD scenario & no_norm 0.10308599472045898 seconds ---\n",
      "HE\n",
      "--- Inference time:  HE scenario & norm 0.10582256317138672 seconds ---\n",
      "--- Inference time:  HE scenario & no_norm 0.10511589050292969 seconds ---\n",
      "ME\n",
      "--- Inference time:  ME scenario & norm 0.1263124942779541 seconds ---\n",
      "--- Inference time:  ME scenario & no_norm 0.11719846725463867 seconds ---\n",
      "SAT\n",
      "--- Inference time:  SAT scenario & norm 0.09247756004333496 seconds ---\n",
      "--- Inference time:  SAT scenario & no_norm 0.1329183578491211 seconds ---\n",
      "SR\n",
      "--- Inference time:  SR scenario & norm 0.13116049766540527 seconds ---\n",
      "(1016, 5)\n",
      "AAAAAAAAAAAA\n",
      "--- Inference time:  SR scenario & no_norm 0.12677526473999023 seconds ---\n",
      "WW\n",
      "--- Inference time:  WW scenario & norm 0.1293201446533203 seconds ---\n",
      "(996, 5)\n",
      "AAAAAAAAAAAA\n",
      "--- Inference time:  WW scenario & no_norm 0.13158583641052246 seconds ---\n"
     ]
    }
   ],
   "source": [
    "n_trees_tested = 1000\n",
    "results = dict()\n",
    "inf_times = dict()\n",
    "mae_dict = dict()\n",
    "\n",
    "for i in n_tips:\n",
    "    print('---', i, 'tips ---')\n",
    "    results[i] = dict()\n",
    "    inf_times[i] = dict()\n",
    "    mae_dict[i] = dict()\n",
    "    \n",
    "    for label in np.unique(data[i]['div_info_test']):\n",
    "        div_scenario = label.split('/')[1].split('_')[0]\n",
    "        results[i][div_scenario] = dict()\n",
    "        inf_times[i][div_scenario] = dict()\n",
    "        mae_dict[i][div_scenario] = dict()\n",
    "        \n",
    "        norm_types = ['norm', 'no_norm']\n",
    "        for norm in norm_types:\n",
    "            results[i][div_scenario][norm] = dict()\n",
    "            inf_times[i][div_scenario][norm] = dict()\n",
    "            mae_dict[i][div_scenario][norm] = dict()\n",
    "            \n",
    "            # Load regression model \n",
    "            model_path = res_path + div_scenario + '/' + i + \"_regression_\"\n",
    "            if norm != 'no_norm':\n",
    "                model_path += norm + '_'\n",
    "            \n",
    "            results[i][div_scenario][norm], ex_time = generate_reg_results(model_path, data[i]['X_test'],\n",
    "                                                                           data[i]['y_reg_test'],\n",
    "                                                                           data[i]['y_reg_norm_test'],\n",
    "                                                                           data[i]['div_info_test'],\n",
    "                                                                           data[i]['resc_factor_test'],\n",
    "                                                                           div_scenario, label, norm)\n",
    "            inf_times[i][div_scenario][norm] = ex_time\n",
    "            \n",
    "            ##### NEW CODE #####\n",
    "            nn_model = load_model(model_path + 'model.keras')\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "            pred = nn_model.predict(np.expand_dims(data[i]['X_test'][data[i]['div_info_test'] == label], axis=2))\n",
    "            \n",
    "            if norm == 'norm':\n",
    "                norm_text = '_norm'\n",
    "            else:\n",
    "                norm_text = ''\n",
    "            y_reg_test = data[i]['y_reg' + norm_text + '_test'][data[i]['div_info_test'] == label]\n",
    "            y_reg_test = [np.array(elem) for elem in y_reg_test]\n",
    "            \n",
    "            real = y_reg_test\n",
    "            error = abs(pred-real)\n",
    "            \n",
    "            resc_factor_test = data[i]['resc_factor_test'][data[i]['div_info_test'] == label]\n",
    "            \n",
    "            if norm == 'norm':\n",
    "                mae_dict[i][div_scenario][norm]['mae_rescaled'] = np.mean(error, axis=0)\n",
    "                \n",
    "                \n",
    "                if div_scenario == \"BD\" or div_scenario == \"HE\" or div_scenario == \"SAT\":\n",
    "                    \n",
    "                    pred[:, 0] = pred[:, 0] / resc_factor_test\n",
    "    \n",
    "                elif div_scenario == \"ME\":\n",
    "                    \n",
    "                    pred[:, 0] = pred[:, 0] / resc_factor_test\n",
    "                    pred[:, 2] = pred[:, 2] / resc_factor_test\n",
    "  \n",
    "                else:\n",
    "        \n",
    "                    pred[:, 0] = pred[:, 0] / resc_factor_test\n",
    "                    pred[:, 1] = pred[:, 1] / resc_factor_test\n",
    "                    pred[:, 4] = pred[:, 4] / resc_factor_test\n",
    "                    \n",
    "                y_reg_test = data[i]['y_reg_test'][data[i]['div_info_test'] == label]\n",
    "                y_reg_test = [np.array(elem) for elem in y_reg_test]\n",
    "                \n",
    "                real = y_reg_test\n",
    "                error = abs(pred-real)\n",
    "                \n",
    "                mae_dict[i][div_scenario][norm]['mae'] = np.mean(error, axis=0)\n",
    "                \n",
    "            else: \n",
    "            \n",
    "                mae_dict[i][div_scenario][norm]['mae'] = np.mean(error, axis=0)\n",
    "                \n",
    "                if div_scenario == \"BD\" or div_scenario == \"HE\" or div_scenario == \"SAT\":\n",
    "                    \n",
    "                    pred[:, 0] = pred[:, 0] * resc_factor_test\n",
    "    \n",
    "                elif div_scenario == \"ME\":\n",
    "\n",
    "                    pred[:, 0] = pred[:, 0] * resc_factor_test\n",
    "                    pred[:, 2] = pred[:, 2] * resc_factor_test\n",
    "  \n",
    "                else:\n",
    "                    \n",
    "                    pred[:, 0] = pred[:, 0] * resc_factor_test\n",
    "                    pred[:, 1] = pred[:, 1] * resc_factor_test\n",
    "                    pred[:, 4] = pred[:, 4] * resc_factor_test\n",
    "                    \n",
    "                \n",
    "                y_reg_test = data[i]['y_reg_norm_test'][data[i]['div_info_test'] == label]\n",
    "                y_reg_test = [np.array(elem) for elem in y_reg_test]\n",
    "                \n",
    "                real = y_reg_test\n",
    "                error = abs(pred-real)                \n",
    "            \n",
    "                mae_dict[i][div_scenario][norm]['mae_rescaled'] = np.mean(error, axis=0)            \n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-08T09:48:28.880612Z",
     "start_time": "2025-07-08T09:48:28.811598Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mae_rescaled': array([0.07186544, 0.02227895, 0.11367133, 0.09332199, 4.22636319]),\n",
       " 'mae': array([0.06611636, 0.02344743, 0.11367133, 0.09332199, 4.00761877])}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-08T08:59:28.540824Z",
     "start_time": "2025-07-08T08:59:28.462324Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MAE': array([1.22314086, 0.07544485, 1.61966674, 0.40997035]),\n",
       " 'MAE_norm': array([0.61845747, 0.07544485, 0.83216266, 0.22585427])}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[\"674\"][\"BD\"][\"norm\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-01T13:13:56.011362Z",
     "start_time": "2025-07-01T13:13:55.979112Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Inference time statistics for 674:\n",
      "Mean: 0.8089\n",
      "Standard deviation: 0.8767\n",
      "Minimum: 0.3100\n",
      "Maximum: 2.7660\n",
      "\n",
      "Inference time statistics for 489:\n",
      "Mean: 0.2203\n",
      "Standard deviation: 0.0696\n",
      "Minimum: 0.1487\n",
      "Maximum: 0.3595\n",
      "\n",
      "Inference time statistics for 87:\n",
      "Mean: 0.1388\n",
      "Standard deviation: 0.0221\n",
      "Minimum: 0.0950\n",
      "Maximum: 0.1602\n"
     ]
    }
   ],
   "source": [
    "for i in inf_times:\n",
    "    t = []\n",
    "    for scenario in inf_times[i]:\n",
    "        t.append(inf_times[i][scenario]['norm'])\n",
    "   \n",
    "    print(f\"\\nInference time statistics for {i}:\")\n",
    "    print(f\"Mean: {np.mean(t):.4f}\")\n",
    "    print(f\"Standard deviation: {np.std(t):.4f}\")\n",
    "    print(f\"Minimum: {np.min(t):.4f}\")\n",
    "    print(f\"Maximum: {np.max(t):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-01T13:13:56.053386Z",
     "start_time": "2025-07-01T13:13:56.013280Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training times for 674 tips\n",
      "-----\n",
      "Mean: 92.79047838846843\n",
      "Std Dev: 11.50902236923396\n",
      "Max: 108.95637226104736\n",
      "Min: 78.42817187309265\n",
      "\n",
      "Training times for 489 tips\n",
      "-----\n",
      "Mean: 147.82049945990244\n",
      "Std Dev: 48.91674298602154\n",
      "Max: 243.39358139038086\n",
      "Min: 103.69829964637756\n",
      "\n",
      "Training times for 87 tips\n",
      "-----\n",
      "Mean: 138.14758396148682\n",
      "Std Dev: 52.42740244921074\n",
      "Max: 212.1332881450653\n",
      "Min: 77.02222275733948\n"
     ]
    }
   ],
   "source": [
    "for i in n_tips:\n",
    "    train_times = []\n",
    "    \n",
    "    for label in np.unique(data[i]['div_info_test']):\n",
    "        div_scenario = label.split('/')[1].split('_')[0]\n",
    "        \n",
    "        # Load regression model \n",
    "        model_path = res_path + div_scenario + '/' + i + \"_regression_norm_\"\n",
    "\n",
    "        with open(model_path + 'model_data.pkl', 'rb') as f:\n",
    "            n_params, train_time = pickle.load(f)\n",
    "                \n",
    "        train_times.append(train_time)\n",
    "    \n",
    "    print('\\nTraining times for', i, 'tips')\n",
    "    print('-'*5)\n",
    "    print('Mean:', np.mean(train_times))\n",
    "    print('Std Dev:', np.std(train_times))\n",
    "    print('Max:', np.max(train_times))\n",
    "    print('Min:', np.min(train_times))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression metrics MAE vs MAE_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-01T13:13:56.081625Z",
     "start_time": "2025-07-01T13:13:56.054748Z"
    }
   },
   "outputs": [],
   "source": [
    "#div_scenario = list(results[list(results.keys())[0]].keys())\n",
    "#get_regression_norm_results(results, '674', div_scenario, 'norm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-01T13:13:56.111598Z",
     "start_time": "2025-07-01T13:13:56.083121Z"
    }
   },
   "outputs": [],
   "source": [
    "#div_scenario = list(results[list(results.keys())[0]].keys())\n",
    "#get_regression_norm_results(results, '489', div_scenario, 'norm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-01T13:13:56.141608Z",
     "start_time": "2025-07-01T13:13:56.113042Z"
    }
   },
   "outputs": [],
   "source": [
    "#div_scenario = list(results[list(results.keys())[0]].keys())\n",
    "#get_regression_norm_results(results, '87', div_scenario, 'norm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison between diversification scenarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-08T10:47:22.340267Z",
     "start_time": "2025-07-08T10:47:22.236827Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------674---------\n",
      "BD\n",
      "         r      a\n",
      "MAE 0.1263 0.0754\n",
      "HE\n",
      "         r      a\n",
      "MAE 0.2087 0.0181\n",
      "ME\n",
      "         r      a   time   frac\n",
      "MAE 0.0356 0.0679 5.0582 0.0489\n",
      "SAT\n",
      "     lambda 0\n",
      "MAE    0.0656\n",
      "SR\n",
      "        r0     r1     a0     a1   time\n",
      "MAE 0.0661 0.0234 0.1137 0.0933 4.0076\n",
      "WW\n",
      "        r0     r1     a0     a1   time\n",
      "MAE 0.0339 0.1077 0.1472 0.0873 2.8722\n",
      "---------489---------\n",
      "BD\n",
      "         r      a\n",
      "MAE 0.1351 0.0744\n",
      "HE\n",
      "         r      a\n",
      "MAE 0.2271 0.0191\n",
      "ME\n",
      "         r      a   time   frac\n",
      "MAE 0.0333 0.0710 5.0218 0.0488\n",
      "SAT\n",
      "     lambda 0\n",
      "MAE    0.0705\n",
      "SR\n",
      "        r0     r1     a0     a1   time\n",
      "MAE 0.0556 0.0209 0.1033 0.0954 3.1034\n",
      "WW\n",
      "        r0     r1     a0     a1   time\n",
      "MAE 0.0322 0.1075 0.1243 0.0851 2.8025\n",
      "---------87---------\n",
      "BD\n",
      "         r      a\n",
      "MAE 0.2558 0.1120\n",
      "HE\n",
      "         r      a\n",
      "MAE 0.3786 0.0246\n",
      "ME\n",
      "         r      a   time   frac\n",
      "MAE 0.0377 0.0926 5.6389 0.0502\n",
      "SAT\n",
      "     lambda 0\n",
      "MAE    0.1776\n",
      "SR\n",
      "        r0     r1     a0     a1   time\n",
      "MAE 0.0736 0.0211 0.1024 0.0904 3.2904\n",
      "WW\n",
      "        r0     r1     a0     a1   time\n",
      "MAE 0.0323 0.1296 0.1381 0.0912 3.0111\n"
     ]
    }
   ],
   "source": [
    "n_tips = ['674', '489', '87']\n",
    "labels = ['BD', 'HE', 'ME', 'SAT', 'SR', 'WW']\n",
    "for tip in n_tips: \n",
    "    print(\"---------\" + str(tip) + \"---------\" )\n",
    "    for label in labels: \n",
    "        print(label)\n",
    "        data = new_get_regression_div_results(mae_dict, tip, label, 'norm', 'mae')\n",
    "        print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
