{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-16T14:20:07.265613Z",
     "start_time": "2025-07-16T14:20:07.249327Z"
    }
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-16T14:20:08.220627Z",
     "start_time": "2025-07-16T14:20:08.208012Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/workspace/deep_birth_death/src')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-16T14:20:10.992586Z",
     "start_time": "2025-07-16T14:20:08.856447Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from time import time\n",
    "from dataset_code.load_dataset_vec import *\n",
    "from deep_utils.dataset_utils import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* X_vec_train\n",
    "* X_vec_test\n",
    "* y_class_train\n",
    "* y_class_test\n",
    "* y_reg_train\n",
    "* y_reg_test\n",
    "* y_reg_train_norm\n",
    "* y_reg_test_norm\n",
    "* resc_factor_train\n",
    "* resc_factor_test\n",
    "* div_scenario_train\n",
    "* div_scenario_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load regression data from pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-16T13:39:25.810002Z",
     "start_time": "2025-07-16T13:39:24.917931Z"
    }
   },
   "outputs": [],
   "source": [
    "pickle_files = [\"raw_87_10k.pkl\", \"raw_489_10k.pkl\", \"raw_674_10k.pkl\"]\n",
    "pickle_path_base = \"/workspace/deep_birth_death/deep_learning/pickles/testing_k/\"\n",
    "file = \"raw_674_10k.pkl\"\n",
    "with open(pickle_path_base + file, 'rb') as f:\n",
    "    dataset = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-16T14:14:44.087614Z",
     "start_time": "2025-07-16T14:14:44.048215Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80000\n"
     ]
    }
   ],
   "source": [
    "print(len(dataset.norm_frac1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-16T14:14:31.832260Z",
     "start_time": "2025-07-16T14:14:31.791937Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['X_vec', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', 'a0', 'a1', 'frac0', 'frac1', 'label', 'label_names', 'lambda0', 'lambda1', 'mu0', 'mu1', 'norm_a0', 'norm_a1', 'norm_frac0', 'norm_frac1', 'norm_lambda0', 'norm_lambda1', 'norm_mu0', 'norm_mu1', 'norm_r0', 'norm_r1', 'norm_time', 'r0', 'r1', 'reg_values', 'resc_factor', 'time']\n"
     ]
    }
   ],
   "source": [
    "print(dir(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-16T14:20:27.787675Z",
     "start_time": "2025-07-16T14:20:21.039726Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/deep_birth_death/src/deep_utils/dataset_utils.py:18: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return np.array(a_permuted), np.array(b_permuted), np.array(c_permuted), \\\n",
      "/workspace/deep_birth_death/src/deep_utils/dataset_utils.py:19: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  np.array(d_permuted), np.array(e_permuted), np.array(f_permuted)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 87_10k.pkl\n",
      "X_train: (54000, 87)\n",
      "X_test: (6000, 87)\n",
      "y_class_train: (54000, 6)\n",
      "y_class_test: (6000, 6)\n",
      "y_reg_train: (54000,)\n",
      "y_reg_test: (6000,)\n",
      "y_reg_norm_train: (54000,)\n",
      "y_reg_norm_test: (6000,)\n",
      "resc_factor_train: (54000,)\n",
      "resc_factor_test: (6000,)\n",
      "div_info_train: (54000,)\n",
      "div_info_test: (6000,)\n",
      "\n",
      " 489_10k.pkl\n",
      "X_train: (54000, 489)\n",
      "X_test: (6000, 489)\n",
      "y_class_train: (54000, 6)\n",
      "y_class_test: (6000, 6)\n",
      "y_reg_train: (54000,)\n",
      "y_reg_test: (6000,)\n",
      "y_reg_norm_train: (54000,)\n",
      "y_reg_norm_test: (6000,)\n",
      "resc_factor_train: (54000,)\n",
      "resc_factor_test: (6000,)\n",
      "div_info_train: (54000,)\n",
      "div_info_test: (6000,)\n",
      "\n",
      " 674_10k.pkl\n",
      "X_train: (54000, 674)\n",
      "X_test: (6000, 674)\n",
      "y_class_train: (54000, 6)\n",
      "y_class_test: (6000, 6)\n",
      "y_reg_train: (54000,)\n",
      "y_reg_test: (6000,)\n",
      "y_reg_norm_train: (54000,)\n",
      "y_reg_norm_test: (6000,)\n",
      "resc_factor_train: (54000,)\n",
      "resc_factor_test: (6000,)\n",
      "div_info_train: (54000,)\n",
      "div_info_test: (6000,)\n"
     ]
    }
   ],
   "source": [
    "pickle_path_base = \"/workspace/deep_birth_death/deep_learning/pickles/testing_k/testing_k_sims/\"\n",
    "pickle_files = [\"raw_87_10k.pkl\", \"raw_489_10k.pkl\", \"raw_674_10k.pkl\"]\n",
    "\n",
    "test_perc = 0.1\n",
    "\n",
    "\n",
    "\n",
    "for file in pickle_files:\n",
    "    with open(pickle_path_base + file, 'rb') as f:\n",
    "        dataset = pickle.load(f)\n",
    "    \n",
    "    # Process diversification scenario information\n",
    "    div_info = [\"/\".join(dataset.label_names[int(elem)].split('/')[-2:]) for elem in dataset.label]\n",
    "    # Process y classification\n",
    "    y_class = to_categorical(dataset.label, num_classes= int(np.max(dataset.label) + 1))\n",
    "    \n",
    "    # Process y regression\n",
    "    y_reg = []\n",
    "    y_reg_norm = []\n",
    "    for i, label in enumerate(dataset.label):\n",
    "        div_scenario = os.path.basename(dataset.label_names[int(label)]).split('_')[0]\n",
    "\n",
    "        # Predict different labels for different simulations\n",
    "        if div_scenario=='BD' or div_scenario=='HE':\n",
    "            y_reg.append([dataset.r0[i], dataset.a0[i]])\n",
    "            y_reg_norm.append([dataset.norm_r0[i], dataset.a0[i]])\n",
    "\n",
    "        elif div_scenario=='ME':\n",
    "            y_reg.append([dataset.r0[i], dataset.a0[i],\n",
    "                          dataset.time[i], dataset.frac1[i]])\n",
    "            y_reg_norm.append([dataset.norm_r0[i], dataset.a0[i],\n",
    "                               dataset.norm_time[i], dataset.frac1[i]])\n",
    "\n",
    "        elif div_scenario=='SR' or div_scenario=='WW':\n",
    "            y_reg.append([dataset.r0[i], dataset.r1[i], dataset.a0[i], dataset.a1[i],\n",
    "                          dataset.time[i]])\n",
    "            y_reg_norm.append([dataset.norm_r0[i], dataset.norm_r1[i], dataset.a0[i], dataset.a1[i],\n",
    "                          dataset.norm_time[i]])\n",
    "\n",
    "        elif div_scenario=='SAT':\n",
    "            y_reg.append([dataset.r0[i]])\n",
    "            y_reg_norm.append([dataset.norm_r0[i]])\n",
    "    \n",
    "    X_vec, y_class, y_reg, y_reg_norm, resc_factor, div_info = shuffle_six_arrays(dataset.X_vec,\n",
    "                                                                                  y_class,\n",
    "                                                                                  y_reg,\n",
    "                                                                                  y_reg_norm,\n",
    "                                                                                  dataset.resc_factor,\n",
    "                                                                                  div_info)\n",
    "    \n",
    "    X_train = X_vec[int(test_perc*len(X_vec)):]\n",
    "    X_test = X_vec[:int(test_perc*len(X_vec))]\n",
    "    y_class_train = y_class[int(test_perc*len(y_class)):]\n",
    "    y_class_test = y_class[:int(test_perc*len(y_class))]\n",
    "    y_reg_train = y_reg[int(test_perc*len(y_reg)):]\n",
    "    y_reg_test = y_reg[:int(test_perc*len(y_reg))]\n",
    "    y_reg_norm_train = y_reg_norm[int(test_perc*len(y_reg_norm)):]\n",
    "    y_reg_norm_test = y_reg_norm[:int(test_perc*len(y_reg_norm))]\n",
    "    resc_factor_train = resc_factor[int(test_perc*len(resc_factor)):]\n",
    "    resc_factor_test = resc_factor[:int(test_perc*len(resc_factor))]\n",
    "    div_info_train = div_info[int(test_perc*len(div_info)):]\n",
    "    div_info_test = div_info[:int(test_perc*len(div_info))]\n",
    "    \n",
    "    print('\\n', file[4:])\n",
    "    data = dict()\n",
    "    data['X_train'] = X_train\n",
    "    data['X_test'] = X_test\n",
    "    data['y_class_train'] = y_class_train\n",
    "    data['y_class_test'] = y_class_test\n",
    "    data['y_reg_train'] = y_reg_train\n",
    "    data['y_reg_test'] = y_reg_test\n",
    "    data['y_reg_norm_train'] = y_reg_norm_train\n",
    "    data['y_reg_norm_test'] = y_reg_norm_test\n",
    "    data['resc_factor_train'] = resc_factor_train\n",
    "    data['resc_factor_test'] = resc_factor_test\n",
    "    data['div_info_train'] = div_info_train\n",
    "    data['div_info_test'] = div_info_test\n",
    "    \n",
    "    print('X_train:', np.shape(data['X_train']))\n",
    "    print('X_test:', np.shape(data['X_test']))\n",
    "    print('y_class_train:', np.shape(data['y_class_train']))\n",
    "    print('y_class_test:', np.shape(data['y_class_test']))\n",
    "    print('y_reg_train:', np.shape(data['y_reg_train']))\n",
    "    print('y_reg_test:', np.shape(data['y_reg_test']))\n",
    "    print('y_reg_norm_train:', np.shape(data['y_reg_norm_train']))\n",
    "    print('y_reg_norm_test:', np.shape(data['y_reg_norm_test']))\n",
    "    print('resc_factor_train:', np.shape(data['resc_factor_train']))\n",
    "    print('resc_factor_test:', np.shape(data['resc_factor_test']))\n",
    "    print('div_info_train:', np.shape(data['div_info_train']))\n",
    "    print('div_info_test:', np.shape(data['div_info_test']))\n",
    "\n",
    "    with open(pickle_path_base + \"dataset_\" + file[4:], 'wb') as f:\n",
    "              pickle.dump(data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "315.4px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
