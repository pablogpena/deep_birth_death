{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T15:18:20.568855Z",
     "start_time": "2025-07-15T15:18:20.548374Z"
    }
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T15:18:20.859654Z",
     "start_time": "2025-07-15T15:18:20.843418Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/workspace/deep_birth_death/src/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T15:18:24.041129Z",
     "start_time": "2025-07-15T15:18:22.204827Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import itertools\n",
    "import time\n",
    "import os\n",
    "import statistics\n",
    "from time import time\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from evaluation.regression import generate_reg_results, get_regression_norm_results, get_regression_div_results, new_get_regression_div_results\n",
    "\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T15:18:25.691173Z",
     "start_time": "2025-07-15T15:18:25.660264Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.options.display.float_format = \"{:,.4f}\".format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T11:09:55.760603Z",
     "start_time": "2025-07-15T11:09:52.813103Z"
    }
   },
   "outputs": [],
   "source": [
    "pickle_base = '/workspace/deep_birth_death/deep_learning/pickles/old_sims/dataset_'\n",
    "res_path = \"/workspace/deep_birth_death/deep_learning//models/reg/\"\n",
    "n_tips = ['674', '489', '87']\n",
    "\n",
    "data = dict()\n",
    "for i in n_tips:\n",
    "    with open(pickle_base + i + \"_10k.pkl\", 'rb') as f:\n",
    "        data[i] = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T11:11:05.275701Z",
     "start_time": "2025-07-15T11:10:11.131972Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 674 tips ---\n",
      "--- Inference time:  BD scenario & norm 0.7340707778930664 seconds ---\n",
      "--- Inference time:  BD scenario & no_norm 0.564518928527832 seconds ---\n",
      "--- Inference time:  HE scenario & norm 0.4966442584991455 seconds ---\n",
      "--- Inference time:  HE scenario & no_norm 0.5091707706451416 seconds ---\n",
      "--- Inference time:  ME scenario & norm 0.5616073608398438 seconds ---\n",
      "--- Inference time:  ME scenario & no_norm 0.5463552474975586 seconds ---\n",
      "--- Inference time:  SAT scenario & norm 0.5446991920471191 seconds ---\n",
      "--- Inference time:  SAT scenario & no_norm 0.5543639659881592 seconds ---\n",
      "--- Inference time:  SR scenario & norm 0.5880281925201416 seconds ---\n",
      "--- Inference time:  SR scenario & no_norm 0.6389503479003906 seconds ---\n",
      "--- Inference time:  WW scenario & norm 0.5798633098602295 seconds ---\n",
      "--- Inference time:  WW scenario & no_norm 0.6010549068450928 seconds ---\n",
      "--- 489 tips ---\n",
      "--- Inference time:  BD scenario & norm 0.42298340797424316 seconds ---\n",
      "--- Inference time:  BD scenario & no_norm 0.33609890937805176 seconds ---\n",
      "--- Inference time:  HE scenario & norm 0.3513054847717285 seconds ---\n",
      "--- Inference time:  HE scenario & no_norm 0.3869912624359131 seconds ---\n",
      "--- Inference time:  ME scenario & norm 0.4040048122406006 seconds ---\n",
      "--- Inference time:  ME scenario & no_norm 0.3432629108428955 seconds ---\n",
      "--- Inference time:  SAT scenario & norm 0.3837001323699951 seconds ---\n",
      "--- Inference time:  SAT scenario & no_norm 0.3461446762084961 seconds ---\n",
      "--- Inference time:  SR scenario & norm 0.4091455936431885 seconds ---\n",
      "--- Inference time:  SR scenario & no_norm 0.4135565757751465 seconds ---\n",
      "--- Inference time:  WW scenario & norm 0.45535898208618164 seconds ---\n",
      "--- Inference time:  WW scenario & no_norm 0.39304375648498535 seconds ---\n",
      "--- 87 tips ---\n",
      "--- Inference time:  BD scenario & norm 0.23601722717285156 seconds ---\n",
      "--- Inference time:  BD scenario & no_norm 0.24762701988220215 seconds ---\n",
      "--- Inference time:  HE scenario & norm 0.2230517864227295 seconds ---\n",
      "--- Inference time:  HE scenario & no_norm 0.2503931522369385 seconds ---\n",
      "--- Inference time:  ME scenario & norm 0.27182769775390625 seconds ---\n",
      "--- Inference time:  ME scenario & no_norm 0.2951321601867676 seconds ---\n",
      "--- Inference time:  SAT scenario & norm 0.23926591873168945 seconds ---\n",
      "--- Inference time:  SAT scenario & no_norm 0.26653528213500977 seconds ---\n",
      "--- Inference time:  SR scenario & norm 0.289029598236084 seconds ---\n",
      "--- Inference time:  SR scenario & no_norm 0.30376720428466797 seconds ---\n",
      "--- Inference time:  WW scenario & norm 0.3022139072418213 seconds ---\n",
      "--- Inference time:  WW scenario & no_norm 0.2977626323699951 seconds ---\n"
     ]
    }
   ],
   "source": [
    "n_trees_tested = 1000\n",
    "results = dict()\n",
    "inf_times = dict()\n",
    "mae_dict = dict()\n",
    "\n",
    "for i in n_tips:\n",
    "    print('---', i, 'tips ---')\n",
    "    results[i] = dict()\n",
    "    inf_times[i] = dict()\n",
    "    mae_dict[i] = dict()\n",
    "    \n",
    "    for label in np.unique(data[i]['div_info_test']):\n",
    "        div_scenario = label.split('/')[1].split('_')[0]\n",
    "        results[i][div_scenario] = dict()\n",
    "        inf_times[i][div_scenario] = dict()\n",
    "        mae_dict[i][div_scenario] = dict()\n",
    "        \n",
    "        norm_types = ['norm', 'no_norm']\n",
    "        for norm in norm_types:\n",
    "            results[i][div_scenario][norm] = dict()\n",
    "            inf_times[i][div_scenario][norm] = dict()\n",
    "            mae_dict[i][div_scenario][norm] = dict()\n",
    "            \n",
    "            # Load regression model \n",
    "            model_path = res_path + div_scenario + '/' + i + \"_regression_\"\n",
    "            if norm != 'no_norm':\n",
    "                model_path += norm + '_'\n",
    "            \n",
    "            results[i][div_scenario][norm], ex_time = generate_reg_results(model_path, data[i]['X_test'],\n",
    "                                                                           data[i]['y_reg_test'],\n",
    "                                                                           data[i]['y_reg_norm_test'],\n",
    "                                                                           data[i]['div_info_test'],\n",
    "                                                                           data[i]['resc_factor_test'],\n",
    "                                                                           div_scenario, label, norm)\n",
    "            inf_times[i][div_scenario][norm] = ex_time\n",
    "            \n",
    "            ##### NEW CODE #####\n",
    "            nn_model = load_model(model_path + 'model.keras')\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "            pred = nn_model.predict(np.expand_dims(data[i]['X_test'][data[i]['div_info_test'] == label], axis=2))\n",
    "            \n",
    "            if norm == 'norm':\n",
    "                norm_text = '_norm'\n",
    "            else:\n",
    "                norm_text = ''\n",
    "            y_reg_test = data[i]['y_reg' + norm_text + '_test'][data[i]['div_info_test'] == label]\n",
    "            y_reg_test = [np.array(elem) for elem in y_reg_test]\n",
    "            \n",
    "            real = y_reg_test\n",
    "            error = abs(pred-real)\n",
    "            \n",
    "            resc_factor_test = data[i]['resc_factor_test'][data[i]['div_info_test'] == label]\n",
    "            \n",
    "            if norm == 'norm':\n",
    "                mae_dict[i][div_scenario][norm]['mae_rescaled'] = np.mean(error, axis=0)\n",
    "                \n",
    "                \n",
    "                if div_scenario == \"BD\" or div_scenario == \"HE\" or div_scenario == \"SAT\":\n",
    "                    \n",
    "                    pred[:, 0] = pred[:, 0] / resc_factor_test\n",
    "    \n",
    "                elif div_scenario == \"ME\":\n",
    "                    \n",
    "                    pred[:, 0] = pred[:, 0] / resc_factor_test\n",
    "                    pred[:, 2] = pred[:, 2] / resc_factor_test\n",
    "  \n",
    "                else:\n",
    "        \n",
    "                    pred[:, 0] = pred[:, 0] / resc_factor_test\n",
    "                    pred[:, 1] = pred[:, 1] / resc_factor_test\n",
    "                    pred[:, 4] = pred[:, 4] / resc_factor_test\n",
    "                    \n",
    "                y_reg_test = data[i]['y_reg_test'][data[i]['div_info_test'] == label]\n",
    "                y_reg_test = [np.array(elem) for elem in y_reg_test]\n",
    "                \n",
    "                real = y_reg_test\n",
    "                error = abs(pred-real)\n",
    "                \n",
    "                mae_dict[i][div_scenario][norm]['mae'] = np.mean(error, axis=0)\n",
    "                \n",
    "            else: \n",
    "            \n",
    "                mae_dict[i][div_scenario][norm]['mae'] = np.mean(error, axis=0)\n",
    "                \n",
    "                if div_scenario == \"BD\" or div_scenario == \"HE\" or div_scenario == \"SAT\":\n",
    "                    \n",
    "                    pred[:, 0] = pred[:, 0] * resc_factor_test\n",
    "    \n",
    "                elif div_scenario == \"ME\":\n",
    "\n",
    "                    pred[:, 0] = pred[:, 0] * resc_factor_test\n",
    "                    pred[:, 2] = pred[:, 2] * resc_factor_test\n",
    "  \n",
    "                else:\n",
    "                    \n",
    "                    pred[:, 0] = pred[:, 0] * resc_factor_test\n",
    "                    pred[:, 1] = pred[:, 1] * resc_factor_test\n",
    "                    pred[:, 4] = pred[:, 4] * resc_factor_test\n",
    "                    \n",
    "                \n",
    "                y_reg_test = data[i]['y_reg_norm_test'][data[i]['div_info_test'] == label]\n",
    "                y_reg_test = [np.array(elem) for elem in y_reg_test]\n",
    "                \n",
    "                real = y_reg_test\n",
    "                error = abs(pred-real)                \n",
    "            \n",
    "                mae_dict[i][div_scenario][norm]['mae_rescaled'] = np.mean(error, axis=0)            \n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T11:11:05.401812Z",
     "start_time": "2025-07-15T11:11:05.278553Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Inference time statistics for 674:\n",
      "Mean: 0.5842\n",
      "Standard deviation: 0.0733\n",
      "Minimum: 0.4966\n",
      "Maximum: 0.7341\n",
      "\n",
      "Inference time statistics for 489:\n",
      "Mean: 0.4044\n",
      "Standard deviation: 0.0322\n",
      "Minimum: 0.3513\n",
      "Maximum: 0.4554\n",
      "\n",
      "Inference time statistics for 87:\n",
      "Mean: 0.2602\n",
      "Standard deviation: 0.0293\n",
      "Minimum: 0.2231\n",
      "Maximum: 0.3022\n"
     ]
    }
   ],
   "source": [
    "for i in inf_times:\n",
    "    t = []\n",
    "    for scenario in inf_times[i]:\n",
    "        t.append(inf_times[i][scenario]['norm'])\n",
    "   \n",
    "    print(f\"\\nInference time statistics for {i}:\")\n",
    "    print(f\"Mean: {np.mean(t):.4f}\")\n",
    "    print(f\"Standard deviation: {np.std(t):.4f}\")\n",
    "    print(f\"Minimum: {np.min(t):.4f}\")\n",
    "    print(f\"Maximum: {np.max(t):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T11:11:05.519870Z",
     "start_time": "2025-07-15T11:11:05.404689Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training times for 674 tips\n",
      "-----\n",
      "Mean: 97.20514261722565\n",
      "Std Dev: 16.59524491937827\n",
      "Max: 120.57813763618469\n",
      "Min: 74.6568374633789\n",
      "\n",
      "Training times for 489 tips\n",
      "-----\n",
      "Mean: 146.4811460574468\n",
      "Std Dev: 48.40481179340226\n",
      "Max: 250.31157898902893\n",
      "Min: 99.37144064903259\n",
      "\n",
      "Training times for 87 tips\n",
      "-----\n",
      "Mean: 145.38835227489471\n",
      "Std Dev: 70.85414399153025\n",
      "Max: 270.30372190475464\n",
      "Min: 76.76596403121948\n"
     ]
    }
   ],
   "source": [
    "for i in n_tips:\n",
    "    train_times = []\n",
    "    \n",
    "    for label in np.unique(data[i]['div_info_test']):\n",
    "        div_scenario = label.split('/')[1].split('_')[0]\n",
    "        \n",
    "        # Load regression model \n",
    "        model_path = res_path + div_scenario + '/' + i + \"_regression_norm_\"\n",
    "\n",
    "        with open(model_path + 'model_data.pkl', 'rb') as f:\n",
    "            n_params, train_time = pickle.load(f)\n",
    "                \n",
    "        train_times.append(train_time)\n",
    "    \n",
    "    print('\\nTraining times for', i, 'tips')\n",
    "    print('-'*5)\n",
    "    print('Mean:', np.mean(train_times))\n",
    "    print('Std Dev:', np.std(train_times))\n",
    "    print('Max:', np.max(train_times))\n",
    "    print('Min:', np.min(train_times))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression metrics MAE vs MAE_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T11:11:05.670558Z",
     "start_time": "2025-07-15T11:11:05.522386Z"
    }
   },
   "outputs": [],
   "source": [
    "#div_scenario = list(results[list(results.keys())[0]].keys())\n",
    "#get_regression_norm_results(results, '674', div_scenario, 'norm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T11:11:05.803180Z",
     "start_time": "2025-07-15T11:11:05.672176Z"
    }
   },
   "outputs": [],
   "source": [
    "#div_scenario = list(results[list(results.keys())[0]].keys())\n",
    "#get_regression_norm_results(results, '489', div_scenario, 'norm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T11:11:05.933008Z",
     "start_time": "2025-07-15T11:11:05.804641Z"
    }
   },
   "outputs": [],
   "source": [
    "#div_scenario = list(results[list(results.keys())[0]].keys())\n",
    "#get_regression_norm_results(results, '87', div_scenario, 'norm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison between diversification scenarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T11:11:06.396596Z",
     "start_time": "2025-07-15T11:11:05.935048Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------674---------\n",
      "BD\n",
      "         r      a\n",
      "MAE 0.1263 0.0754\n",
      "HE\n",
      "         r      a\n",
      "MAE 0.2087 0.0181\n",
      "ME\n",
      "         r      a   time   frac\n",
      "MAE 0.0356 0.0679 5.0581 0.0489\n",
      "SAT\n",
      "     lambda 0\n",
      "MAE    0.0656\n",
      "SR\n",
      "        r0     r1     a0     a1   time\n",
      "MAE 0.0661 0.0234 0.1137 0.0933 4.0077\n",
      "WW\n",
      "        r0     r1     a0     a1   time\n",
      "MAE 0.0339 0.1077 0.1472 0.0873 2.8722\n",
      "---------489---------\n",
      "BD\n",
      "         r      a\n",
      "MAE 0.1351 0.0744\n",
      "HE\n",
      "         r      a\n",
      "MAE 0.2271 0.0191\n",
      "ME\n",
      "         r      a   time   frac\n",
      "MAE 0.0333 0.0710 5.0220 0.0488\n",
      "SAT\n",
      "     lambda 0\n",
      "MAE    0.0705\n",
      "SR\n",
      "        r0     r1     a0     a1   time\n",
      "MAE 0.0556 0.0209 0.1033 0.0954 3.1034\n",
      "WW\n",
      "        r0     r1     a0     a1   time\n",
      "MAE 0.0322 0.1075 0.1243 0.0851 2.8023\n",
      "---------87---------\n",
      "BD\n",
      "         r      a\n",
      "MAE 0.2558 0.1120\n",
      "HE\n",
      "         r      a\n",
      "MAE 0.3786 0.0246\n",
      "ME\n",
      "         r      a   time   frac\n",
      "MAE 0.0377 0.0926 5.6388 0.0502\n",
      "SAT\n",
      "     lambda 0\n",
      "MAE    0.1776\n",
      "SR\n",
      "        r0     r1     a0     a1   time\n",
      "MAE 0.0736 0.0211 0.1024 0.0904 3.2904\n",
      "WW\n",
      "        r0     r1     a0     a1   time\n",
      "MAE 0.0323 0.1296 0.1381 0.0912 3.0111\n"
     ]
    }
   ],
   "source": [
    "n_tips = ['674', '489', '87']\n",
    "labels = ['BD', 'HE', 'ME', 'SAT', 'SR', 'WW']\n",
    "for tip in n_tips: \n",
    "    print(\"---------\" + str(tip) + \"---------\" )\n",
    "    for label in labels: \n",
    "        print(label)\n",
    "        data = new_get_regression_div_results(mae_dict, tip, label, 'norm', 'mae')\n",
    "        print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
